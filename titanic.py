# -*- coding: utf-8 -*-
"""titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W6wM_9ATLRok_pn0lmfllYGo9DBcRWLN
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import pandas as pd
import numpy as np
from tensorflow.keras import layers
from sklearn import preprocessing

"""#TITANIC"""

#Read data set
data = pd.read_csv('train.csv')
inputs = pd.DataFrame(data, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Fare'])
outputs = pd.DataFrame(data, columns = ['Survived']).iloc[:, :].values

#fill with median, nan fields in Age
inputs['Age'] = inputs['Age'].fillna(inputs['Age'].median())
dummy_encoded_train_predictors = pd.get_dummies(inputs)

#Trasnform data to numerical type
input_values = dummy_encoded_train_predictors.iloc[:, :].values
y = outputs

#normalizing data in inputs
x = preprocessing.MinMaxScaler().fit_transform(input_values)

#Create a base model -- sequential, functional, or subclass.
model = tf.keras.Sequential([
    layers.Dense(30, activation='relu'),
    layers.Dense(10, activation='sigmoid'),
    layers.Dense(5, 'relu'),
    layers.Dense(1)
])

# Configure a model for mean-squared error regression.
model.compile(optimizer='adam',
              loss='mse',       # mean squared error
              metrics=['accuracy']) 

model.fit(x, y, epochs=50, batch_size=40)#, verbose=0)

data_evaluate = pd.read_csv('test.csv')
inputs_evaluate = pd.DataFrame(data_evaluate, columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Fare'])

inputs_evaluate['Age'] = inputs_evaluate['Age'].fillna(inputs_evaluate['Age'].median())
inputs_evaluate['Fare'] = inputs_evaluate['Fare'].fillna(inputs_evaluate['Fare'].median())
inputs_evaluate['Embarked'] = inputs_evaluate['Embarked'].fillna('S')
dummy_encoded_train_evaluate = pd.get_dummies(inputs_evaluate)

input_evaluate = dummy_encoded_train_evaluate.iloc[:, :].values

#normalizing data in inputs_evaluate
x_evaluate = preprocessing.MinMaxScaler().fit_transform(input_evaluate)

predictions = model.predict(x_evaluate)
output_csv = pd.DataFrame({
    'PassengerId': data_evaluate.PassengerId,
    'Survived': np.absolute(np.around(predictions.T[0])).astype(int)
})
output_csv.to_csv(path_or_buf='./gender_submission.csv',index=False)